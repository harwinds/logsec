<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Upload CSV Data to Elasticsearch | logsec</title><meta name=keywords content><meta name=description content="Recently, I&rsquo;ve been working on understanding and detecting Log4j vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html by Nik Alleyne on his blog securitynik.com.
To detect outbound traffic going to IOC&rsquo;s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:
1. First create a new index logs-threat-intel Using the Dev Tools in Kibana, isse the Create Index API"><meta name=author content><link rel=canonical href=https://www.logsec.cloud/posts/upload-csv-to-elastic/><link crossorigin=anonymous href=/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Upload CSV Data to Elasticsearch"><meta property="og:description" content="Recently, I&rsquo;ve been working on understanding and detecting Log4j vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html by Nik Alleyne on his blog securitynik.com.
To detect outbound traffic going to IOC&rsquo;s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:
1. First create a new index logs-threat-intel Using the Dev Tools in Kibana, isse the Create Index API"><meta property="og:type" content="article"><meta property="og:url" content="https://www.logsec.cloud/posts/upload-csv-to-elastic/"><meta property="og:image" content="https://www.logsec.cloud/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-12-28T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-28T00:00:00+00:00"><meta property="og:site_name" content="logsec"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.logsec.cloud/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Upload CSV Data to Elasticsearch"><meta name=twitter:description content="Recently, I&rsquo;ve been working on understanding and detecting Log4j vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html by Nik Alleyne on his blog securitynik.com.
To detect outbound traffic going to IOC&rsquo;s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:
1. First create a new index logs-threat-intel Using the Dev Tools in Kibana, isse the Create Index API"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://www.logsec.cloud/posts/"},{"@type":"ListItem","position":3,"name":"Upload CSV Data to Elasticsearch","item":"https://www.logsec.cloud/posts/upload-csv-to-elastic/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Upload CSV Data to Elasticsearch","name":"Upload CSV Data to Elasticsearch","description":"Recently, I\u0026rsquo;ve been working on understanding and detecting Log4j vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html by Nik Alleyne on his blog securitynik.com.\nTo detect outbound traffic going to IOC\u0026rsquo;s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:\n1. First create a new index logs-threat-intel Using the Dev Tools in Kibana, isse the Create Index API","keywords":[],"articleBody":"Recently, I’ve been working on understanding and detecting Log4j vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html by Nik Alleyne on his blog securitynik.com.\nTo detect outbound traffic going to IOC’s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:\n1. First create a new index logs-threat-intel Using the Dev Tools in Kibana, isse the Create Index API\nPUT /logs-threat-intel\r{\r\"settings\": {\r\"number_of_shards\": 1\r},\r\"mappings\": {\r\"properties\": {\r\"ioc.ip\": { \"type\": \"ip\" },\r\"ioc.url\": { \"type\": \"keyword\" },\r\"threatintel.indicator.signature\": {\"type\": \"keyword\"},\r\"@timestamp\":{ \"type\" : \"date\", \"format\" : \"strict_date_optional_time_nanos\"},\r\"event.ingested\":{ \"type\" : \"date\", \"format\" : \"strict_date_optional_time_nanos\"},\r\"event.module\": {\"type\": \"keyword\"},\r\"event.category\": {\"type\": \"keyword\"},\r\"event.type\": {\"type\": \"keyword\"},\r\"event.kind\": {\"type\": \"keyword\"}\r}\r}\r} 2. Create a new Ingest Node Pipeline logs-threat-intel-pipeline Ingest pipelines let you perform common transformations on your data before indexing. For example, you can use pipelines to remove fields, extract values from text, and enrich your data.\nPUT _ingest/pipeline/logs-threat-intel-pipeline\r{\r\"description\": \"Ingest Pipeline for the index logs-threat-intel\",\r\"processors\": [\r{\r\"set\": {\r\"field\": \"@timestamp\",\r\"value\": \"{{_ingest.timestamp}}\"\r}\r},\r{\r\"set\": {\r\"field\": \"event.ingested\",\r\"value\": \"{{_ingest.timestamp}}\"\r}\r},\r{\r\"set\": {\r\"field\": \"event.module\",\r\"value\": \"threatintel\"\r}\r},\r{\r\"set\": {\r\"field\": \"event.category\",\r\"value\": \"threat\"\r}\r},\r{\r\"set\": {\r\"field\": \"event.type\",\r\"value\": \"indicator\"\r}\r},\r{\r\"set\": {\r\"field\": \"event.kind\",\r\"value\": \"enrichment\"\r}\r}\r]\r} 3. Next, map the Ingest Node Pipeline created in Step 2 with the index created in Step 1. PUT logs-threat-intel/_settings\r{\r\"index.default_pipeline\": \"logs-threat-intel-pipeline\"\r} 4. Example on how to ingest new IOC’s POST logs-threat-intel/_doc/1\r{\r\"ioc.ip\": \"\"\r} POST logs-threat-intel/_doc/2\r{\r\"ioc.url\": \"\"\r} Replace the IPv4/IPv6 and URL with respective IP or urls. Above technique works, but not quite scalable if we need ingest a big list of IOC’s. As an example, we need to ingest Log4j CSV downloaded from Microsoft blog. To achieve that, wrote this 4 liner bash script:\nwhile read f1 do curl -k -X POST 'https://:9200/logs-threat-intel/_doc/?pretty' -H \"Content-Type: application/json\" -u : -d \"{ \\\"ioc.ip\\\": \\\"$f1\\\", \\\"threatintel.indicator.signature\\\": \\\"log4j\\\"}\" done \u003e /dev/null 2\u003e\u00261 \u0026 \u003c log4j-ioc.csv Above script reads the contents of the file log4j-ioc.csv one at a time and ingest to elasticsearch under the index logs-threat-intel.\nReferences: Create index API: https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html Create or update pipeline API: https://www.elastic.co/guide/en/elasticsearch/reference/current/put-pipeline-api.html ","wordCount":"390","inLanguage":"en","datePublished":"2021-12-28T00:00:00Z","dateModified":"2021-12-28T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.logsec.cloud/posts/upload-csv-to-elastic/"},"publisher":{"@type":"Organization","name":"logsec","logo":{"@type":"ImageObject","url":"https://www.logsec.cloud/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://www.logsec.cloud accesskey=h title="logsec (Alt + H)">logsec</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://www.logsec.cloud/ title=posts><span>posts</span></a></li><li><a href=https://www.logsec.cloud/pages/about title=about><span>about</span></a></li><li><a href=https://www.logsec.cloud/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://www.logsec.cloud>Home</a>&nbsp;»&nbsp;<a href=https://www.logsec.cloud/posts/>Posts</a></div><h1 class=post-title>Upload CSV Data to Elasticsearch</h1><div class=post-meta><span title='2021-12-28 00:00:00 +0000 UTC'>December 28, 2021</span>&nbsp;·&nbsp;2 min</div></header><div class=post-content><p>Recently, I&rsquo;ve been working on understanding and detecting <a href=https://logging.apache.org/log4j/2.x/>Log4j</a> vulnerability using Elasticsearch. If you want to know more about this vulnerability, I would suggest read the blog series <a href=https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html>https://www.securitynik.com/2021/12/beginning-log4-shell-understanding.html</a> by Nik Alleyne on his blog <a href=https://www.securitynik.com/>securitynik.com</a>.</p><p>To detect outbound traffic going to IOC&rsquo;s related to Log4j, needed to upload a csv data to Elasticsearch. To achieve that I followed the following steps:</p><h3 id=1-first-create-a-new-index-logs-threat-intel>1. First create a new index <code>logs-threat-intel</code><a hidden class=anchor aria-hidden=true href=#1-first-create-a-new-index-logs-threat-intel>#</a></h3><p>Using the <code>Dev Tools</code> in Kibana, isse the Create Index API</p><pre tabindex=0><code>PUT /logs-threat-intel
{
  &#34;settings&#34;: {
    &#34;number_of_shards&#34;: 1
  },
  &#34;mappings&#34;: {
    &#34;properties&#34;: {
      &#34;ioc.ip&#34;: { &#34;type&#34;: &#34;ip&#34; },
      &#34;ioc.url&#34;: { &#34;type&#34;: &#34;keyword&#34; },
      &#34;threatintel.indicator.signature&#34;: {&#34;type&#34;: &#34;keyword&#34;},
      &#34;@timestamp&#34;:{ &#34;type&#34; : &#34;date&#34;, &#34;format&#34; : &#34;strict_date_optional_time_nanos&#34;},
      &#34;event.ingested&#34;:{ &#34;type&#34; : &#34;date&#34;, &#34;format&#34; : &#34;strict_date_optional_time_nanos&#34;},
      &#34;event.module&#34;: {&#34;type&#34;: &#34;keyword&#34;},
      &#34;event.category&#34;: {&#34;type&#34;: &#34;keyword&#34;},
      &#34;event.type&#34;: {&#34;type&#34;: &#34;keyword&#34;},
      &#34;event.kind&#34;: {&#34;type&#34;: &#34;keyword&#34;}
    }
  }
}
</code></pre><h3 id=2-create-a-new-ingest-node-pipeline-logs-threat-intel-pipeline>2. Create a new Ingest Node Pipeline <code>logs-threat-intel-pipeline</code><a hidden class=anchor aria-hidden=true href=#2-create-a-new-ingest-node-pipeline-logs-threat-intel-pipeline>#</a></h3><p><a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/ingest.html>Ingest pipelines</a> let you perform common transformations on your data before indexing. For example, you can use pipelines to remove fields, extract values from text, and enrich your data.</p><pre tabindex=0><code>PUT _ingest/pipeline/logs-threat-intel-pipeline
{
  &#34;description&#34;: &#34;Ingest Pipeline for the index logs-threat-intel&#34;,
  &#34;processors&#34;: [
    {
      &#34;set&#34;: {
        &#34;field&#34;: &#34;@timestamp&#34;,
        &#34;value&#34;: &#34;{{_ingest.timestamp}}&#34;
      }
    },
        {
      &#34;set&#34;: {
        &#34;field&#34;: &#34;event.ingested&#34;,
        &#34;value&#34;: &#34;{{_ingest.timestamp}}&#34;
      }
    },
    {
      &#34;set&#34;: {
         &#34;field&#34;: &#34;event.module&#34;,
         &#34;value&#34;: &#34;threatintel&#34;
      }
    },
    {
      &#34;set&#34;: {
      &#34;field&#34;: &#34;event.category&#34;,
      &#34;value&#34;: &#34;threat&#34;
      }
    },
    {
      &#34;set&#34;: {
        &#34;field&#34;: &#34;event.type&#34;,
        &#34;value&#34;: &#34;indicator&#34;
      }
    },
    {
      &#34;set&#34;: {
         &#34;field&#34;: &#34;event.kind&#34;,
         &#34;value&#34;: &#34;enrichment&#34;
      }
    }
  ]
}
</code></pre><h3 id=3-next-map-the-ingest-node-pipeline-created-in-step-2-with-the-index-created-in-step-1>3. Next, map the Ingest Node Pipeline created in Step 2 with the index created in Step 1.<a hidden class=anchor aria-hidden=true href=#3-next-map-the-ingest-node-pipeline-created-in-step-2-with-the-index-created-in-step-1>#</a></h3><pre tabindex=0><code>PUT logs-threat-intel/_settings
{
  &#34;index.default_pipeline&#34;: &#34;logs-threat-intel-pipeline&#34;
}
</code></pre><h3 id=4-example-on-how-to-ingest-new-iocs>4. Example on how to ingest new IOC&rsquo;s<a hidden class=anchor aria-hidden=true href=#4-example-on-how-to-ingest-new-iocs>#</a></h3><pre tabindex=0><code>POST logs-threat-intel/_doc/1
{
    &#34;ioc.ip&#34;: &#34;&lt;IPv4/IPv6&gt;&#34;
}
</code></pre><pre tabindex=0><code>POST logs-threat-intel/_doc/2
{
    &#34;ioc.url&#34;: &#34;&lt;URL&gt;&#34;
}
</code></pre><p>Replace the <code>IPv4/IPv6</code> and <code>URL</code> with respective IP or urls. Above technique works, but not quite scalable if we need ingest a big list of IOC&rsquo;s. As an example, we need to ingest <a href=https://raw.githubusercontent.com/Azure/Azure-Sentinel/master/Sample%20Data/Feeds/Log4j_IOC_List.csv>Log4j CSV</a> downloaded from <a href=https://www.microsoft.com/security/blog/2021/12/11/guidance-for-preventing-detecting-and-hunting-for-cve-2021-44228-log4j-2-exploitation/#IOC>Microsoft blog</a>. To achieve that, wrote this 4 liner bash script:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>while</span> read f1
</span></span><span style=display:flex><span><span style=color:#66d9ef>do</span>        
</span></span><span style=display:flex><span>   curl -k -X POST <span style=color:#e6db74>&#39;https://&lt;ELASTICSEARCH_URL/ELASTICSEARCH_IP&gt;:9200/logs-threat-intel/_doc/?pretty&#39;</span> -H <span style=color:#e6db74>&#34;Content-Type: application/json&#34;</span> -u &lt;USERNAME&gt;:&lt;PASSWORD&gt; -d <span style=color:#e6db74>&#34;{ \&#34;ioc.ip\&#34;: \&#34;</span>$f1<span style=color:#e6db74>\&#34;, \&#34;threatintel.indicator.signature\&#34;: \&#34;log4j\&#34;}&#34;</span>
</span></span><span style=display:flex><span>   <span style=color:#66d9ef>done</span> &gt; /dev/null 2&gt;&amp;<span style=color:#ae81ff>1</span> &amp; &lt; log4j-ioc.csv
</span></span></code></pre></div><p>Above script reads the contents of the file <code>log4j-ioc.csv</code> one at a time and ingest to elasticsearch under the index <code>logs-threat-intel</code>.</p><h3 id=references>References:<a hidden class=anchor aria-hidden=true href=#references>#</a></h3><ul><li>Create index API: <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html>https://www.elastic.co/guide/en/elasticsearch/reference/current/indices-create-index.html</a></li><li>Create or update pipeline API: <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/put-pipeline-api.html>https://www.elastic.co/guide/en/elasticsearch/reference/current/put-pipeline-api.html</a></li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://www.logsec.cloud/posts/cross-account-access-codecommit-repo/><span class=title>« Prev</span><br><span>Configure cross-account access from an EC2 Instance to an AWS CodeCommit repo using roles</span></a>
<a class=next href=https://www.logsec.cloud/posts/git-workflow-automation/><span class=title>Next »</span><br><span>GitHub Workflow Automation Script</span></a></nav></footer><script src=https://giscus.app/client.js data-repo=harwinds/logsec data-repo-id=R_kgDOGjnARg data-category=Announcements data-category-id=DIC_kwDOGjnARs4CAWru data-mapping=title data-reactions-enabled=1 data-emit-metadata=0 data-theme=dark data-lang=en crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://www.logsec.cloud>logsec</a></span>
<span>Powered:
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>